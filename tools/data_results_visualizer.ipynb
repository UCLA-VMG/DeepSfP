{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Visualization Tool\n",
    "\n",
    "We provide this tool for visualizing samples in our polar image / surface normal dataset (see more on dataset [here](https://github.com/alexrgilbert/deepsfp/blob/master/data/README.md)). It can used for examining data before and after transformations, generated crop indices (see more on data preparation [here](https://github.com/alexrgilbert/deepsfp/blob/master/README.md)), as well as test set reconstructions and test results. \n",
    "\n",
    "You can use the same configuration override/command line options process for specifying the dataset to use (see *'Set Config'* cell below). \n",
    "\n",
    "Outputs are [optionally] saved to `$SfP_ROOT/<$cfg.output_dir>/<$cfg.(train|test).dataloader.dataset.name>/<$EXPERIMENT_ID>`, where experiment IDs are of the following forms:\n",
    "\n",
    "- Data Visualization:` <$CONFIG_FILENAME>_<$TIME_STRING>_(mat|pth)-data-viz`\n",
    "- Crop Visualization: `<$CONFIG_FILENAME>_<$TIME_STRING>_<crop_h>-<crop_w>-<thresh>-crop-idcs-viz`\n",
    "- Test Reconstruction Visualization + Test Results: `<$CONFIG_FILENAME>_<$TIME_STRING>_pred-viz`\n",
    "\n",
    "Along with the saved visualizations (if specified), will be the following meta-data files (for reproducing visualization runs):\n",
    "\n",
    "- Frozen Config (`<$EXPERIMENT_ID>.yaml`): YAML configuration override file with the exact configuration used for this conversion run.\n",
    "- Frozen Train/Test Split (`(train|test)_set.csv`): Copy of the training or test set data list (specified by `<$data_cfg.root>/<$data_cfg.name>/<$data_cfg.data_list>>` where `data_cfg = <$cfg.(train|test).dataloader.dataset>`).\n",
    "- Log file (`<$EXPERIMENT_ID>.log`): Includes a printout of the current commit hash for this repo, the experiment config, and logging messages from the process."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "import scipy.io as sio\n",
    "from matplotlib import pyplot as plt\n",
    "from matplotlib.gridspec import GridSpec\n",
    "from mpl_toolkits.axes_grid1 import make_axes_locatable\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "from yacs.config import CfgNode as CN\n",
    "from __init__ import config as default_config, update_config, setup_experiment"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_mat(filename):\n",
    "    sample = sio.loadmat(filename)\n",
    "    proc = lambda arr : torch.from_numpy(np.atleast_3d(arr).transpose((2,0,1)))\n",
    "    sample = {k: proc(v) for k,v in sample.items() if k[:2] != '__'}\n",
    "    # Key name changes\n",
    "    sample['est'] = sample['normals_prior']\n",
    "    sample['image'] = sample['images']\n",
    "    sample['label'] = sample['normals_gt']\n",
    "    return sample\n",
    "\n",
    "\n",
    "def load_pth(filename):\n",
    "    return torch.load(filename)\n",
    "\n",
    "\n",
    "def normalize_normals(normals):\n",
    "    normalsn = normals - torch.min(normals)\n",
    "    normalsm = normalsn / (torch.max(normalsn) + 1e-8)\n",
    "    return normalsm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Set Config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "CONFIG_PATH = '../experiments/deepsfp.yaml' # Default: None\n",
    "OPTS = []  # Default: []\n",
    "OPTS += ['enable_tblogging', 'False']  # Disable TB-logging for visualiation runs\n",
    "config = update_config(default_config.clone(), config_filepath=CONFIG_PATH, cli_options=OPTS, )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualize Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _viz_polar_images(images, axes=None):\n",
    "    # Plot polar images\n",
    "    if axes is None:\n",
    "        _, ax_arr = plt.subplots(2,2)\n",
    "        axes = [ax_arr[i//2][i%2] for i in range(4)]\n",
    "    angles = [0,45,90,135]\n",
    "    for i in range(len(images)):\n",
    "        img,ax = images[i], axes[i]\n",
    "        ax.imshow(img)\n",
    "        ax.set_title(f'Polar Image @ {angles[i]}°')\n",
    "\n",
    "\n",
    "def _viz_mask(mask, ax=None):\n",
    "    # Plot Binary Mask\n",
    "    if ax is None:\n",
    "        _, ax = plt.subplots(1,1)\n",
    "    ax.imshow(mask[0])\n",
    "    ax.set_title(f'Binary Foreground Mask')\n",
    "\n",
    "\n",
    "def _viz_normals_gt(normals, ax=None):\n",
    "    # Plot normal GT\n",
    "    if ax is None:\n",
    "        _, ax = plt.subplots(1,1)\n",
    "    ax.imshow(normalize_normals(normals).permute(1,2,0))\n",
    "    ax.set_title(f'Normals GT')\n",
    "\n",
    "\n",
    "def _viz_normals_prior(normals, axes=None):\n",
    "    # Plot normal priors\n",
    "    if axes is None:\n",
    "        _, axes = plt.subplots(1,3)\n",
    "    solution_type = ['Diffuse', 'Specular 1', 'Specular 2']\n",
    "    for i in range(len(normals)//3):\n",
    "        normal,ax = normals[(3*i):(3*i)+3], axes[i]\n",
    "        ax.imshow(normalize_normals(normal).permute(1,2,0))\n",
    "        ax.set_title(f'Normals Prior:\\n{solution_type[i]} Solution')\n",
    "\n",
    "\n",
    "def visualize_data(sample, sample_name=None, figsize=(12,12), disp=False, dest_dir=None, logger=None):\n",
    "    # Setup\n",
    "    fig = plt.figure(constrained_layout=True, figsize=figsize)\n",
    "    fig.tight_layout()\n",
    "    if sample_name is not None:\n",
    "        fig.suptitle(f'{sample_name}', y=1.01)\n",
    "    gs = GridSpec(3, 3, figure=fig)\n",
    "    \n",
    "    # Polar images\n",
    "    polar_image_axes = [fig.add_subplot(gs[i//2,i%2]) for i in range(4)]\n",
    "    _viz_polar_images(sample['image'], axes=polar_image_axes)\n",
    "    \n",
    "    # Binary Mask\n",
    "    binary_mask_ax = fig.add_subplot(gs[0,2])\n",
    "    _viz_mask(sample['mask'], ax=binary_mask_ax)\n",
    "    \n",
    "    # Normals GT\n",
    "    normals_gt_ax = fig.add_subplot(gs[1,2])\n",
    "    _viz_normals_gt(sample['label'], ax=normals_gt_ax)\n",
    "    \n",
    "    # Normals Priors\n",
    "    normals_prior_axes = [fig.add_subplot(gs[2,i]) for i in range(3)]\n",
    "    _viz_normals_prior(sample['est'], axes=normals_prior_axes)\n",
    "    \n",
    "    # Display / Saving / Cleanup\n",
    "    if disp:\n",
    "        plt.show()\n",
    "    if dest_dir is not None:\n",
    "        dest = os.path.join(dest_dir,f\"{sample_name.replace('/','-')}.png\")\n",
    "        if logger is not None:\n",
    "            logger.info(f'\\tSaving data viz to {os.path.realpath(dest)}')\n",
    "        fig.savefig(dest, facecolor='w')\n",
    "    plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "FIGSIZE=(12,12)\n",
    "DISP=True\n",
    "SAVE=True\n",
    "\n",
    "PHASE = 'test'  # 'train' or 'test'\n",
    "PTH_FILES = False  # Whether to visualize transformed data (i.e. converted from .mat to .pth, \n",
    "                   # see https://github.com/alexrgilbert/deepsfp/blob/master/README.md)\n",
    "\n",
    "load = load_pth if PTH_FILES else load_mat\n",
    "\n",
    "datacfg = config.get(PHASE).dataloader.dataset\n",
    "dataroot, dataset, datafile = datacfg.root, datacfg.name, datacfg.data_list\n",
    "datadir = os.path.join('..', dataroot, dataset)\n",
    "obj_dir = os.path.join(datadir, 'objects')\n",
    "\n",
    "logger, exp_dir, _, _, _ = setup_experiment(config, CONFIG_PATH, root_dir='..', \n",
    "        quiet=True, phase=PHASE, name=f'{PHASE}-set-{\"pth\" if PTH_FILES else \"mat\"}-data-viz',\n",
    "        meta=[{'config_override_filepath': CONFIG_PATH, 'cli_config_overrides': OPTS}, config])\n",
    "print(f'See {exp_dir} for logs{\" and plots\" if SAVE else \"\"}.')  # Logging will be silent because, Jupyter\n",
    "\n",
    "logger.info(f'Visualizing the \"{dataset}\" {PHASE} dataset located at {os.path.realpath(dataroot)}.')\n",
    "datalist = pd.read_csv(os.path.join(datadir,datafile), header=None, squeeze=True)\n",
    "ext = '.pth' if PTH_FILES else '.mat'\n",
    "datalist = datalist.apply(lambda f: f'{os.path.splitext(f)[0]}{ext}')\n",
    "pbar = tqdm(datalist)\n",
    "for i, filename in enumerate(pbar):\n",
    "    pbar.set_description(filename)\n",
    "    logger.info(f'[{i+1}/{len(datalist)}] Visualizing {filename}...')\n",
    "    filepath = os.path.join(obj_dir, filename)\n",
    "    if not os.path.exists(filepath):\n",
    "        logger.warning(f'{filepath} does not exist! Skipping!')\n",
    "        continue\n",
    "    sample = load_pth(filepath) if PTH_FILES else load_mat(filepath)\n",
    "    visualize_data(sample, sample_name=filename, figsize=FIGSIZE, disp=DISP, dest_dir=exp_dir, logger=logger)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualize Random Crops\n",
    "\n",
    "Read more on random crop idices [here](https://github.com/alexrgilbert/deepsfp/blob/master/README.md). Must be generated before this block can be run."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def viz_crop_masks(sample, sample_name, crop_idcs, crop_h_w, n=5, figsize=(12,12), disp=False, dest_dir=None, logger=None):\n",
    "    sel = np.random.randint(0,len(crop_idcs),n**2)\n",
    "    top_left = crop_idcs[sel,:].data\n",
    "    gt = normalize_normals(sample['label'])\n",
    "    fig,axes = plt.subplots(n,n, figsize=figsize)\n",
    "    fig.suptitle(f'[{sample_name}] Random {crop_h_w[0]}x{crop_h_w[1]} Crops of GT Normals', y=1.0)\n",
    "    fig.tight_layout()\n",
    "    for i in range(n**2):\n",
    "        ax = axes[i//n][i%n]\n",
    "        top,left = top_left[i]\n",
    "        crop = gt[:,top: top + crop_h_w[0], left: left + crop_h_w[1]]\n",
    "        ax.imshow(crop.permute(1,2,0))\n",
    "        ax.set_title(f'({top},{left})->({top+crop_h_w[0]},{left+crop_h_w[1]})')\n",
    "    if disp:\n",
    "        plt.show()\n",
    "    if dest_dir is not None:\n",
    "        dest = os.path.join(dest_dir,f\"{sample_name.replace('/','-')}.png\")\n",
    "        if logger is not None:\n",
    "            logger.info(f'\\tSaving crop mask viz to {os.path.realpath(dest)}')\n",
    "        fig.savefig(dest, facecolor='w')\n",
    "    plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "FIGSIZE=(12,12)\n",
    "DISP=True\n",
    "SAVE=True\n",
    "\n",
    "PHASE = 'test' # 'train' or 'test'\n",
    "N = 5  # Sqrt of total number of random crops to sample and visualize\n",
    "\n",
    "\n",
    "datacfg = config.get(PHASE).dataloader.dataset\n",
    "dataroot, dataset, datafile = datacfg.root, datacfg.name, datacfg.data_list\n",
    "datadir = os.path.join('..', dataroot, dataset)\n",
    "objdir = os.path.join(datadir, 'objects')\n",
    "assert 'RandomCrop' in datacfg.transforms, f'No RandomCrop configured for {PHASE} phase!'\n",
    "cropcfg = datacfg.transforms.RandomCrop\n",
    "crop_h,crop_w = cropcfg.crop_size\n",
    "thresh = cropcfg.foreground_ratio_threshold\n",
    "idcsdir = os.path.join(datadir, 'crop_indices',f'{crop_h}_{crop_w}_{thresh}')\n",
    "\n",
    "logger, exp_dir, _, _, _ = setup_experiment(config, CONFIG_PATH, root_dir='..', quiet=True, phase=PHASE,\n",
    "                         name=f'{PHASE}-set-{crop_h}-{crop_w}-{str(thresh).replace(\".\",\"_\")}-crop-idcs-viz',\n",
    "                        meta=[{'config_override_filepath': CONFIG_PATH, 'cli_config_overrides': OPTS}, config])\n",
    "\n",
    "print(f'See {exp_dir} for logs{\" and plots\" if SAVE else \"\"}.')\n",
    "logger.info(f'Visualizing crop indices for crops of dimensions {crop_h}x{crop_w} with foreground '\n",
    "            f'ratio > {thresh} on the \"{dataset}\" {PHASE} dataset located at '\n",
    "            f'{os.path.realpath(dataroot)}')\n",
    "\n",
    "datalist = pd.read_csv(os.path.join(datadir,datafile),header=None, squeeze=True)\n",
    "datalist = datalist.apply(lambda f: f'{os.path.splitext(f)[0]}.pth')\n",
    "pbar = tqdm(datalist)\n",
    "for i,filename in enumerate(pbar):\n",
    "    pbar.set_description(filename)\n",
    "    logger.info(f'[{i+1}/{len(datalist)}] Visualizing crop masks for {filename}...')\n",
    "    objpath = os.path.join(objdir, filename)\n",
    "    idcspath = os.path.join(idcsdir,filename)\n",
    "    if not os.path.exists(filepath):\n",
    "            logger.warning(f'Object @ {filepath} does not exist! Skipping!')\n",
    "            continue\n",
    "    if not os.path.exists(idcspath):\n",
    "            logger.warning(f'Crop indices @ {filepath} do not exist! Skipping!')\n",
    "            continue\n",
    "    sample = torch.load(objpath)\n",
    "    idcs = torch.load(idcspath)\n",
    "    viz_crop_masks(sample, filename, idcs, (crop_h,crop_w), n=N, \n",
    "                    figsize=FIGSIZE, disp=DISP, dest_dir=exp_dir, logger=logger)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test Reconstructions\n",
    "\n",
    "Visualizing test set reconstructions requires providing the path to a test experiment directory (i.e. `$SfP_ROOT/<$cfg.output_dir>/<$cfg.test.dataloader.dataset.name>/<$CONFIG_FILENAME>_<$TIME_STRING>_test`). The config used for the corresponding test run will be used automatically (the *Set Config* cell above will be ignored) to plot the test set reconstructions (from `reconstructions.pth`) alongside their ground truth normal's.\n",
    "\n",
    "TODO: Currently expects reconstructions represent surface normals. For alternative format, must replace _ae_map."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Path to Test Experiment Directory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "EXPERIMENT_DIRECTORY = ''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "COLORS =  ['r', 'g', 'b', 'c', 'm', 'y', 'k',]\n",
    "\n",
    "def _ae_map(sample, label):\n",
    "    target, mask = label['label'], label['mask']\n",
    "    dot_product = (sample * target).sum(0)\n",
    "    output_norm = torch.norm(sample, dim=0)\n",
    "    target_norm = torch.norm(target, dim=0)\n",
    "    dot_product = (dot_product / (output_norm * target_norm + 1e-8)).clamp(-1, 1)\n",
    "\n",
    "    error_map = torch.acos(dot_product) # [-pi, pi]\n",
    "    angular_map = error_map * 180.0 / np.pi\n",
    "    angular_map = angular_map * mask[0].float()\n",
    "    return angular_map.squeeze()\n",
    "\n",
    "def visualize_reconstruction(sample, label, object_name, figsize=(16,4), disp=False, dest_dir=None, logger=None):\n",
    "    # Setup\n",
    "    fig,axes = plt.subplots(1,4, figsize=figsize)\n",
    "    fig.suptitle(f'{object_name} | MAE = {sample[\"error\"]:.3f}')\n",
    "    fig.tight_layout()\n",
    "\n",
    "    # Black & White (Polar) Image\n",
    "    img_ax = axes[0]\n",
    "    img_ax.imshow(label['image'][0], cmap='gray')\n",
    "    img_ax.set_title(f'Polar Image @ 0°')\n",
    "    \n",
    "    # Reconstruction\n",
    "    sample_ax = axes[1]\n",
    "    pred = normalize_normals(sample['reconstruction'])*label['mask'].float()\n",
    "    sample_ax.imshow(pred.permute(1,2,0))\n",
    "    sample_ax.set_title(f'Reconstruction')\n",
    "\n",
    "    # Angular Error Map\n",
    "    err_ax = axes[2]\n",
    "    err_map = _ae_map(sample['reconstruction'],label)\n",
    "    err_img = err_ax.imshow(err_map.abs(), cmap='Reds', vmin=0, vmax=180)\n",
    "    err_divider = make_axes_locatable(err_ax)\n",
    "    err_cax = err_divider.append_axes(\"right\", size=\"5%\", pad=0.05)\n",
    "    plt.colorbar(err_img, cax=err_cax)\n",
    "    err_ax.set_title(f'Angular Error Map (°)')\n",
    "\n",
    "    # Ground truth\n",
    "    label_ax = axes[3]\n",
    "    gt = normalize_normals(label['label'])*label['mask'].float()\n",
    "    label_ax.imshow(gt.permute(1,2,0))\n",
    "    label_ax.set_title(f'Ground Truth')\n",
    "\n",
    "    # Display & Save\n",
    "    if disp:\n",
    "        plt.show()\n",
    "    if dest_dir is not None:\n",
    "        dest = os.path.join(dest_dir,f\"{object_name}.png\")\n",
    "        if logger is not None:\n",
    "            logger.info(f'\\tSaving reconstruction viz to {os.path.realpath(dest)}')\n",
    "        fig.savefig(dest, facecolor='w')\n",
    "    plt.close()\n",
    "\n",
    "def plot_results(results, exp_name, figsize=(12,16), disp=False, dest_dir=None, logger=None):\n",
    "    # Setup\n",
    "    fig = plt.figure(constrained_layout=True, figsize=figsize)\n",
    "    fig.tight_layout()\n",
    "    gs = GridSpec(4, 3, figure=fig)\n",
    "    df = results.sort_values(['lighting','object','orientation'],axis=0,ascending=False)\n",
    "    fig.suptitle(f'Experiment {exp_name}: Results\\nOverall Avg MAE (°) = {df.error.mean():.3f}', y=.93)\n",
    "    \n",
    "    # MAE by Sample\n",
    "    mbs_ax = fig.add_subplot(gs[:,:1])\n",
    "    s, l, v = lambda ser: ser.sort_index(ascending=False), df.lighting, df.lighting.value_counts()\n",
    "    bars = mbs_ax.barh(range(len(df)), df.error, tick_label=df.iloc[:,1:3].fillna('').agg('_'.join,axis=1), \n",
    "                        label=s(l).to_list(), color=np.repeat(COLORS[:l.nunique()], s(v).to_list()))\n",
    "    mbs_ax.legend(tuple(bars[b] for b in s(v).cumsum().values - 1)[::-1],tuple(s(v).index)[::-1])\n",
    "    for b in bars:\n",
    "        w,y,h = b.get_width(), b.get_y(), b.get_height()\n",
    "        mbs_ax.annotate(f'{w:.2f}',xy=(w, y+h/2), xytext=(3, 0),\n",
    "                    textcoords=\"offset points\", ha='left', va='center')\n",
    "    mbs_ax.minorticks_on()\n",
    "    mbs_ax.tick_params(axis='y', which='minor', left=False)\n",
    "    mbs_ax.grid(axis='x',which='both')\n",
    "    mbs_ax.set_title(f'MAE (°) by Sample')\n",
    "\n",
    "    # MAE by Lighting\n",
    "    mbl_ax = fig.add_subplot(gs[:2,1:])\n",
    "    mbl = df.groupby('lighting')['error'].mean()\n",
    "    bars = mbl_ax.bar(range(len(mbl)), mbl.values, tick_label=mbl.index, color=COLORS[:len(mbl)])#, label=mbl.index.to_list(),)\n",
    "    # mbl_ax.legend(bars,mbl.index.to_list(),loc='lower left')\n",
    "    for b in bars:\n",
    "        h,x,w = b.get_height(), b.get_x(), b.get_width()\n",
    "        mbl_ax.annotate(f'{h:.2f}',xy=(x+w/2, h), xytext=(0, 3),\n",
    "                    textcoords=\"offset points\", ha='center', va='bottom')\n",
    "    mbl_ax.minorticks_on()\n",
    "    mbl_ax.tick_params(axis='x', which='minor', bottom=False)\n",
    "    mbl_ax.grid(axis='y',which='both')\n",
    "    mbl_ax.set_title(f'Average MAE (°) by Lighting Condition')\n",
    "\n",
    "    # MAE by Object\n",
    "    mbo_ax = fig.add_subplot(gs[2:,1:])\n",
    "    mbo = df.groupby(['object','orientation'])['error'].mean()\n",
    "    labels = list(map(lambda t: '_'.join(t), mbo.index.to_list()))\n",
    "    mbo_ax.set_xticklabels(mbo_ax.get_xticks(), rotation = 90)\n",
    "    bars = mbo_ax.bar(range(len(mbo)), mbo.values, tick_label=labels, color=COLORS[:len(mbo)])\n",
    "    for b in bars:\n",
    "        h,x,w = b.get_height(), b.get_x(), b.get_width()\n",
    "        mbo_ax.annotate(f'{h:.2f}',xy=(x+w/2, h), xytext=(0, 3),\n",
    "                    textcoords=\"offset points\", ha='center', va='bottom')\n",
    "    mbo_ax.minorticks_on()\n",
    "    mbo_ax.tick_params(axis='x', which='minor', bottom=False)\n",
    "    mbo_ax.grid(axis='y',which='both')\n",
    "    mbo_ax.set_title(f'Average MAE (°) by Object')\n",
    "\n",
    "    # Display & Save\n",
    "    if disp:\n",
    "        plt.show()\n",
    "    if dest_dir is not None:\n",
    "        dest = os.path.join(dest_dir,f\"results_plots.png\")\n",
    "        if logger is not None:\n",
    "            logger.info(f'\\tSaving results plots to {os.path.realpath(dest)}')\n",
    "        fig.savefig(dest, facecolor='w')\n",
    "    plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "RECONSTRUCTIONS_FIGSIZE=(16,4)\n",
    "RESULTS_FIGSIZE=(12,16)\n",
    "DISP=True\n",
    "SAVE=True\n",
    "RECONSTRUCTIONS = True  # Whether to visualize reconstructions\n",
    "RESULTS = True  # Whether to plot results\n",
    "\n",
    "exp_dir = os.path.realpath(EXPERIMENT_DIRECTORY)\n",
    "exp_id = os.path.basename(exp_dir)\n",
    "config_path = os.path.join(exp_dir,f'{exp_id}.yaml')\n",
    "reconstructions_path = os.path.join(exp_dir, 'reconstructions.pth')\n",
    "results_path = os.path.join(exp_dir, 'results.csv')\n",
    "testset_path = os.path.join(exp_dir, 'test_set.csv')\n",
    "\n",
    "# Load config used for testing\n",
    "with open(config_path, 'r') as config_file:\n",
    "    test_config = CN.load_cfg(config_file)\n",
    "# Disable TB-Logging for visualization run and force set testset list\n",
    "update_config(test_config, cli_options=['enable_tblogging', 'False', \n",
    "                                        'test.dataloader.dataset.data_list', testset_path])\n",
    "\n",
    "logger, exp_dir, _, _, _ = setup_experiment(test_config, config_path, root_dir='..', \n",
    "                                quiet=True, phase='test', name=f'pred-viz', meta=[test_config])\n",
    "dest_dir = exp_dir if SAVE else None\n",
    "print(f'See {exp_dir} for logs{\" and plots\" if SAVE else \"\"}.')\n",
    "\n",
    "if RECONSTRUCTIONS:\n",
    "    logger.info(f'Visualizing test set reconstructions from experiment {exp_id}')\n",
    "    reconstructions = torch.load(reconstructions_path)\n",
    "    datacfg = test_config.test.dataloader.dataset\n",
    "    dataroot, dataset = datacfg.root, datacfg.name\n",
    "    datadir = os.path.join('..', dataroot, dataset)\n",
    "    objdir = os.path.join(datadir, 'objects')\n",
    "    matlist = pd.read_csv(testset_path,header=None, squeeze=True)\n",
    "    pthlist = matlist.apply(lambda f: f'{os.path.splitext(f)[0]}.pth')\n",
    "    pbar = tqdm(pthlist)\n",
    "    for i, filename in enumerate(pbar):\n",
    "        pbar.set_description(filename)\n",
    "        logger.info(f'[{i+1}/{len(pthlist)}] Visualizing {filename}...')\n",
    "        filepath = os.path.join(objdir, filename)\n",
    "        if not os.path.exists(filepath):\n",
    "            logger.warning(f'No ground truth for {filename}! {filepath} does not exist! Skipping!')\n",
    "            continue\n",
    "        objname = os.path.splitext(filename)[0].replace('/','_')\n",
    "        if objname not in reconstructions:\n",
    "            logger.warning(f'No reconstruction for {objname}! Skipping!')\n",
    "            continue\n",
    "        sample = reconstructions[objname]\n",
    "        label = load_pth(filepath)\n",
    "        visualize_reconstruction(sample, label, object_name=objname, figsize=RECONSTRUCTIONS_FIGSIZE, \n",
    "                                 disp=DISP, dest_dir=dest_dir, logger=logger)\n",
    "if RESULTS:\n",
    "    logger.info(f'Visualizing test set results from experiment {exp_id}')\n",
    "    results = pd.read_csv(results_path, index_col=0)\n",
    "    plot_results(results, exp_id, figsize=RESULTS_FIGSIZE, disp=DISP, dest_dir=dest_dir, logger=logger)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
